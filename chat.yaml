query:
  llm: &llm
    type: OpenAILikeConfig
    model: "Qwen3-235B-A22B"
    api_base: "http://localhost:8080/v1"
    # api_base: "http://192.168.50.5:8080/v1"
    context_window: 131072
    temperature: 0.6
    max_tokens: 8192
    timeout: 7200

  engine:
    # type: SimpleQueryEngineConfig

    type: RetrieverQueryEngineConfig
    response_mode: compact_accumulate

    # type: CitationQueryEngineConfig
    # chunk_size: 512
    # chunk_overlap: 20

    # type: RetryQueryEngineConfig
    # evaluator:
    #   type: RelevancyEvaluatorConfig
    #   llm: *llm
    # engine:
    #   type: SimpleQueryEngineConfig

    # type: RetrySourceQueryEngineConfig
    # evaluator:
    #   type: GuidelineConfig
    #   llm: *llm
    # engine:
    #   type: SimpleQueryEngineConfig

chat:
  llm: *llm
  # default_user: "user1"
  # summarize: False
  engine:
    type: SimpleContextChatEngineConfig
    context_window: 32768
    # type: CondensePlusContextChatEngineConfig
    # skip_condense: false

retrieval:
  top_k: 20
  sparse_top_k: 5

  # fusion:
  #   llm: *llm

  # vector_store:
  #   connection: "postgresql+psycopg2://postgres@localhost:5432/vector_db"
  #   hybrid_search: true

  embedding:
    # type: BGEM3EmbeddingConfig

    type: OpenAILikeEmbeddingConfig
    model_name: "bge-m3"
    # model_name: "sentence-transformers/all-MiniLM-L6-v2"
    dimensions: 1024
    api_base: "http://localhost:8080/v1"

    # type: HuggingFaceEmbeddingConfig
    # model_name: "BAAI/bge-base-en-v1.5"

  splitter:
    type: SentenceSplitterConfig
    chunk_size: 512
    chunk_overlap: 20

  extractors: []
    # - type: KeywordExtractorConfig
    #   keywords: 5
    #   llm:
    #     <<: *llm
    #     max_tokens: 100
    # - type: SummaryExtractorConfig
    #   summaries:
    #     - "self"
    #   llm: *llm
    # - type: TitleExtractorConfig
    #   nodes: 5
    #   llm: *llm
    # - type: QuestionsAnsweredExtractorConfig
    #   questions: 3
    #   llm: *llm

  # keywords:
  #   collect: true
  #   llm: *llm
