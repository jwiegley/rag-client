query:
  llm: &llm
    provider: "OpenAILike"
    model: "Qwen3-0.6B"
    base_url: "http://localhost:8080/v1"
    # base_url: "http://192.168.50.5:8080/v1"
    max_tokens: 200
    timeout: 7200
  source_retries: false

chat:
  llm: *llm
  # default_user: "user1"
  # summarize: False
  # engine:
  #   type: SimpleChatEngineConfig

retrieval:
  top_k: 3

  # vector_store:
  #   connection: "postgresql+psycopg2://postgres@localhost:5432/vector_db"
  #   hybrid_search: true

  # embedding:
  #   provider: "BGEM3"
  #   model: "BAAI/bge-m3"
  #   dimensions: 1024
  embedding:
    provider: "HuggingFace"
    # model: "BAAI/bge-large-en-v1.5"
    model: "BAAI/bge-base-en-v1.5"
    dimensions: 512

  splitter:
    type: SentenceSplitterConfig
    chunk_size: 2048
    chunk_overlap: 256

  extractors:
    - type: KeywordExtractorConfig
      keywords: 5
      llm: *llm
    - type: SummaryExtractorConfig
      summaries:
        - "self"
      llm: *llm
    - type: TitleExtractorConfig
      nodes: 5
      llm: *llm
    - type: QuestionsAnsweredExtractorConfig
      questions: 3
      llm: *llm

  keywords:
    collect: true
    llm: *llm
