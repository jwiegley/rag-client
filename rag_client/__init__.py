"""RAG Client - A flexible Python tool for Retrieval-Augmented Generation.

This package provides RAG workflows with support for both ephemeral and
persistent storage modes, designed for integration with local/open-weight models.
"""

# Re-export llama-index types that are commonly used
from llama_index.core import (
    Document,
    KeywordTableIndex,
    SimpleKeywordTableIndex,
    StorageContext,
    VectorStoreIndex,
)
from llama_index.core.base.response.schema import (
    Response,
    StreamingResponse,
)
from llama_index.core.embeddings import BaseEmbedding
from llama_index.core.indices.base import BaseIndex
from llama_index.core.llms import ChatMessage as LlamaChatMessage
from llama_index.core.llms.llm import LLM
from llama_index.core.retrievers import BaseRetriever
from llama_index.core.schema import (
    BaseNode,
    NodeWithScore,
    QueryBundle,
    TextNode,
)
from llama_index.core.storage.chat_store import SimpleChatStore

from .config.models import (  # Embedding configs; LLM configs; Splitter configs; Extractor configs; Other configs; Helper functions
    ChatConfig,
    ChatEngineConfig,
    CitationQueryEngineConfig,
    CodeSplitterConfig,
    CondensePlusContextChatEngineConfig,
    Config,
    ContextChatEngineConfig,
    EmbeddingConfig,
    ExtractorConfig,
    FusionRetrieverConfig,
    HuggingFaceEmbeddingConfig,
    JSONNodeParserConfig,
    KeywordExtractorConfig,
    KeywordsConfig,
    LiteLLMConfig,
    LiteLLMEmbeddingConfig,
    LlamaCPPConfig,
    LlamaCPPEmbeddingConfig,
    LLMConfig,
    LMStudioConfig,
    LoggingConfig,
    MultiStepQueryEngineConfig,
    OllamaConfig,
    OllamaEmbeddingConfig,
    OpenAIConfig,
    OpenAIEmbeddingConfig,
    OpenAILikeConfig,
    OpenAILikeEmbeddingConfig,
    OpenRouterConfig,
    PerplexityConfig,
    PostgresVectorStoreConfig,
    QueryConfig,
    QueryEngineConfig,
    QuestionsAnsweredExtractorConfig,
    RetrievalConfig,
    RetrieverQueryEngineConfig,
    RetryQueryEngineConfig,
    RetrySourceQueryEngineConfig,
    SemanticSplitterConfig,
    SentenceSplitterConfig,
    SentenceWindowSplitterConfig,
    SimpleChatEngineConfig,
    SimpleContextChatEngineConfig,
    SimpleQueryEngineConfig,
    SimpleVectorStoreConfig,
    SplitterConfig,
    SummaryExtractorConfig,
    TitleExtractorConfig,
    VectorStoreConfig,
    embedding_model,
    llm_model,
)
from .core.models import ChatState, QueryState
from .core.workflow import RAGWorkflow
from .exceptions import (
    ConfigurationError,
    DocumentProcessingError,
    EmbeddingError,
    IndexingError,
    LLMError,
    RAGClientError,
    RetrievalError,
    StorageError,
)
from .types import (
    ChatHistory,
    ChatMessage,
    DocumentList,
    Embedding,
    EmbeddingList,
    NodeID,
    QueryResult,
    SearchResult,
    SearchResults,
)
from .utils.helpers import (
    cache_dir,
    clean_special_tokens,
    collection_hash,
    convert_str,
    error,
    list_files,
    parse_prefixes,
    read_files,
)
from .utils.readers import MailParser, OrgReader

__version__ = "0.1.0"

__all__ = [
    # Core classes
    "RAGWorkflow",
    "ChatState",
    "QueryState",
    # Configurations
    "Config",
    "RetrievalConfig",
    "QueryConfig",
    "ChatConfig",
    "LoggingConfig",
    "EmbeddingConfig",
    "HuggingFaceEmbeddingConfig",
    "OllamaEmbeddingConfig",
    "OpenAIEmbeddingConfig",
    "OpenAILikeEmbeddingConfig",
    "LiteLLMEmbeddingConfig",
    "LlamaCPPEmbeddingConfig",
    "LLMConfig",
    "OllamaConfig",
    "OpenAIConfig",
    "OpenAILikeConfig",
    "LiteLLMConfig",
    "LlamaCPPConfig",
    "PerplexityConfig",
    "OpenRouterConfig",
    "LMStudioConfig",
    "SplitterConfig",
    "SentenceSplitterConfig",
    "SentenceWindowSplitterConfig",
    "SemanticSplitterConfig",
    "JSONNodeParserConfig",
    "CodeSplitterConfig",
    "ExtractorConfig",
    "KeywordExtractorConfig",
    "SummaryExtractorConfig",
    "TitleExtractorConfig",
    "QuestionsAnsweredExtractorConfig",
    "KeywordsConfig",
    "VectorStoreConfig",
    "SimpleVectorStoreConfig",
    "PostgresVectorStoreConfig",
    "FusionRetrieverConfig",
    "QueryEngineConfig",
    "ChatEngineConfig",
    "CitationQueryEngineConfig",
    "RetrieverQueryEngineConfig",
    "SimpleQueryEngineConfig",
    "MultiStepQueryEngineConfig",
    "RetrySourceQueryEngineConfig",
    "RetryQueryEngineConfig",
    "SimpleChatEngineConfig",
    "SimpleContextChatEngineConfig",
    "ContextChatEngineConfig",
    "CondensePlusContextChatEngineConfig",
    # Helper functions
    "error",
    "clean_special_tokens",
    "cache_dir",
    "collection_hash",
    "list_files",
    "read_files",
    "convert_str",
    "parse_prefixes",
    "embedding_model",
    "llm_model",
    # Readers
    "OrgReader",
    "MailParser",
    # Exceptions
    "RAGClientError",
    "ConfigurationError",
    "EmbeddingError",
    "LLMError",
    "IndexingError",
    "RetrievalError",
    "StorageError",
    "DocumentProcessingError",
    # Types
    "DocumentList",
    "Embedding",
    "EmbeddingList",
    "NodeID",
    "ChatHistory",
    "ChatMessage",
    "QueryResult",
    "SearchResult",
    "SearchResults",
    # Re-exported llama-index types
    "VectorStoreIndex",
    "SimpleKeywordTableIndex",
    "KeywordTableIndex",
    "StorageContext",
    "Document",
    "Response",
    "StreamingResponse",
    "BaseRetriever",
    "LlamaChatMessage",
    "BaseNode",
    "NodeWithScore",
    "TextNode",
    "QueryBundle",
    "BaseIndex",
    "BaseEmbedding",
    "LLM",
    "SimpleChatStore",
]
